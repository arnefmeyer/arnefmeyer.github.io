<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>lnpy.lnp package &mdash; lnpy 0.1 alpha documentation</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1 alpha',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="lnpy 0.1 alpha documentation" href="index.html" />
    <link rel="up" title="lnpy package" href="lnpy.html" />
    <link rel="next" title="lnpy.transform package" href="lnpy.transform.html" />
    <link rel="prev" title="lnpy.learn package" href="lnpy.learn.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="lnpy.transform.html" title="lnpy.transform package"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="lnpy.learn.html" title="lnpy.learn package"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">lnpy 0.1 alpha documentation</a> &raquo;</li>
          <li><a href="lnpy.html" accesskey="U">lnpy package</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="lnpy-lnp-package">
<h1>lnpy.lnp package<a class="headerlink" href="#lnpy-lnp-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-lnpy.lnp.base">
<span id="lnpy-lnp-base-module"></span><h2>lnpy.lnp.base module<a class="headerlink" href="#module-lnpy.lnp.base" title="Permalink to this headline">¶</a></h2>
<p>A base class for all receptive field estimation methods</p>
<dl class="class">
<dt id="lnpy.lnp.base.LNPEstimator">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.base.</tt><tt class="descname">LNPEstimator</tt><big>(</big><em>fit_bias=True</em>, <em>n_spikefilt=0</em>, <em>n_griditer=5</em>, <em>n_jobs=1</em>, <em>verbose=True</em>, <em>param_grid=None</em>, <em>param_info=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.base.LNPEstimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></tt></p>
<p>Base class for receptive field estimation methods</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>fit_bias</strong> (<em>boolean</em>) &#8211; Fit intercept?</li>
<li><strong>n_griditer</strong> (<em>int</em>) &#8211; Number of grid points used during (cross-validate-based) search
for model hyperparameters</li>
<li><strong>n_jobs</strong> (<em>int</em>) &#8211; The number of workers used during hyperparameter grid search</li>
<li><strong>verbose</strong> (<em>boolean</em>) &#8211; Guess what</li>
<li><strong>param_grid</strong> (<em>dict</em>) &#8211; <p>Dictionary with hyperparameter names (keys) and grid values (values).
Example:</p>
<blockquote>
<div>param_grid = {&#8216;alpha&#8217;: 2 ** np.linspace(-10, 5, 10)}</div></blockquote>
</li>
<li><strong>param_info</strong> (<em>dict</em>) &#8211; <p>Parameter information; currently only scaling is supported but may
also be used to bound parameters. Example:</p>
<blockquote>
<div>param_info = {&#8216;alpha&#8217;: {&#8216;scaling&#8217;: &#8216;log2&#8217;}}</div></blockquote>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lnpy.lnp.base.LNPEstimator.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.base.LNPEstimator.fit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.base.LNPEstimator.get_bias">
<tt class="descname">get_bias</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.base.LNPEstimator.get_bias" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.base.LNPEstimator.get_spikefilt">
<tt class="descname">get_spikefilt</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.base.LNPEstimator.get_spikefilt" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.base.LNPEstimator.get_weights">
<tt class="descname">get_weights</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.base.LNPEstimator.get_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="lnpy.lnp.base.LNPEstimator.name">
<tt class="descname">name</tt><a class="headerlink" href="#lnpy.lnp.base.LNPEstimator.name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.base.LNPEstimator.predict">
<tt class="descname">predict</tt><big>(</big><em>X</em><big>)</big><a class="headerlink" href="#lnpy.lnp.base.LNPEstimator.predict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.base.LNPEstimator.to_string">
<tt class="descname">to_string</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.base.LNPEstimator.to_string" title="Permalink to this definition">¶</a></dt>
<dd><p>Return string representation of method (defaults to name)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lnpy.lnp.base.STRF">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.base.</tt><tt class="descname">STRF</tt><big>(</big><em>*args</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.base.STRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lnpy.html#lnpy.base.Spectrogram" title="lnpy.base.Spectrogram"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.base.Spectrogram</span></tt></a></p>
<p>Convenience class to wrap Specrogram as STRF</p>
<dl class="attribute">
<dt id="lnpy.lnp.base.STRF.intercept">
<tt class="descname">intercept</tt><a class="headerlink" href="#lnpy.lnp.base.STRF.intercept" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.base.STRF.show">
<tt class="descname">show</tt><big>(</big><em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.base.STRF.show" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lnpy.lnp.cbrf">
<span id="lnpy-lnp-cbrf-module"></span><h2>lnpy.lnp.cbrf module<a class="headerlink" href="#module-lnpy.lnp.cbrf" title="Permalink to this headline">¶</a></h2>
<p>A classification-based receptive field estimation algorithm</p>
<p>For details on the CbRF method see:</p>
<p>Meyer AF, Diepenbrock J-P, Happel MFK, Ohl FW, Anemueller J (2014)
Discriminative Learning of Receptive Fields from Responses to Non-Gaussian
Stimulus Ensembles. PLoS ONE 9(4): e93062.</p>
<p>doi: 10.1371/journal.pone.0093062
link: <a class="reference external" href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0093062">http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0093062</a></p>
<p>The SGD-based stochastic approximation scheme has been described in:
Arne AF, Diepenbrock JP, Ohl FW, Anemüller J (2015)
Fast and robust estimation of spectro-temporal receptive fields using
stochastic approximations. Journal of Neuroscience Methods, 246, 119-133.</p>
<p>doi: <a class="reference external" href="http://dx.doi.org/10.1016/j.jneumeth.2015.02.009">http://dx.doi.org/10.1016/j.jneumeth.2015.02.009</a>.
link: <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S0165027015000618">http://www.sciencedirect.com/science/article/pii/S0165027015000618</a></p>
<dl class="class">
<dt id="lnpy.lnp.cbrf.CbRF">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.cbrf.</tt><tt class="descname">CbRF</tt><big>(</big><em>optimize=True</em>, <em>metric='AUC'</em>, <em>prior=&lt;lnpy.learn.pyhelper.PyGaussianPrior object at 0x2b9af3570110&gt;</em>, <em>alpha=1.0</em>, <em>gamma=0.0</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.cbrf.CbRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lnpy.lnp.base.LNPEstimator" title="lnpy.lnp.base.LNPEstimator"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.lnp.base.LNPEstimator</span></tt></a></p>
<p>Classification-based RF estimation class</p>
<p>Computes full solution of the CbRF method by using batch gradient
descent.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimize</strong> (<em>boolean</em>) &#8211; Perform automatic model optimization?</li>
<li><strong>metric</strong> (<em>string</em>) &#8211; The metric used for model optimization, e.g., &#8216;AUC&#8217; or &#8216;MI&#8217;. See
grid_seach module for further metrics.</li>
<li><strong>prior</strong> (<em>Prior</em>) &#8211; Prior of the model, e.g., GaussianPrior or LaplacePrior. See learn
module for further priors</li>
<li><strong>tolerance</strong> (<em>float</em>) &#8211; TRON solver tolerance</li>
<li><strong>gamma</strong> (<em>alpha,</em>) &#8211; Prior hyperparameters</li>
<li><strong>parameters will be passed to the grid search class</strong> (<em>Optional</em>) &#8211; </li>
<li><strong>lnpy.learn.grid_search.ParamSearchCV</strong> &#8211; </li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lnpy.lnp.cbrf.CbRF.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.cbrf.CbRF.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Ttain model and extract parameters</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lnpy.lnp.cbrf.StochasticCbRF">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.cbrf.</tt><tt class="descname">StochasticCbRF</tt><big>(</big><em>optimize=True</em>, <em>metric='AUC'</em>, <em>loss=&lt;lnpy.learn.pyhelper.PySquaredHingeLoss object at 0x2b9afab9ae68&gt;</em>, <em>alpha=1</em>, <em>n_epochs=1</em>, <em>algorithm='sgd'</em>, <em>suffix=''</em>, <em>permutation='auto'</em>, <em>weighting=None</em>, <em>param_range=None</em>, <em>avg_decay=2.0</em>, <em>warm_start=False</em>, <em>eta0=-1</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.cbrf.StochasticCbRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lnpy.lnp.base.LNPEstimator" title="lnpy.lnp.base.LNPEstimator"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.lnp.base.LNPEstimator</span></tt></a></p>
<p>Stochastic gradient descent version of the CbRF method</p>
<p>Approximates the solution to the CbRF method by stochastic gradient
descent (with Gaussian prior)</p>
<blockquote>
<div>Parameters</div></blockquote>
<dl class="docutils">
<dt>optimize <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd>Perform automatic model optimization?</dd>
<dt>metric <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>The metric used for model optimization, e.g., &#8216;AUC&#8217; or &#8216;MI&#8217;</dd>
<dt>loss <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;hinge&#8217;, &#8216;squared_hinge&#8217;, &#8216;log&#8217;}</span></dt>
<dd>Loss function</dd>
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Regularization parameter</dd>
<dt>n_epochs <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Number of SGD iterations over the data set</dd>
<dt>algorithm <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;sgd&#8217;, &#8216;asgd&#8217;}</span></dt>
<dd>Plain SGD (&#8216;sgd&#8217;) or polynomial averaging SGD (&#8216;asgd&#8217;)</dd>
<dt>avg_decay <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>decay factor of asgd algorithm with avg_decay &gt;= 0</dd>
<dt>warm_start <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd>initialize SGD algorithm with current parameters or reset
parameters before each training</dd>
<dt>suffix <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>Prepend string to method name for easier result handling</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd>be verbose</dd>
<dt>param_range <span class="classifier-delimiter">:</span> <span class="classifier">{ndarray, list}</span></dt>
<dd>Prior hyperparameters</dd>
<dt>weighting <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;permutation&#8217;, &#8216;inv_prob&#8217;}</span></dt>
<dd>Permute samples from spike and no spike classes or use inverse
class priors?</dd>
</dl>
<p>Optional parameters will be passed to the grid search class
lnpy.learn.grid_search.ParamSearchCV</p>
<dl class="attribute">
<dt id="lnpy.lnp.cbrf.StochasticCbRF.alpha">
<tt class="descname">alpha</tt><a class="headerlink" href="#lnpy.lnp.cbrf.StochasticCbRF.alpha" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.cbrf.StochasticCbRF.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.cbrf.StochasticCbRF.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train model and extract parameters</p>
</dd></dl>

<dl class="attribute">
<dt id="lnpy.lnp.cbrf.StochasticCbRF.name">
<tt class="descname">name</tt><a class="headerlink" href="#lnpy.lnp.cbrf.StochasticCbRF.name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.cbrf.StochasticCbRF.reset">
<tt class="descname">reset</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.cbrf.StochasticCbRF.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets algorithm parameters to initial values</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lnpy.lnp.fast_tools">
<span id="lnpy-lnp-fast-tools-module"></span><h2>lnpy.lnp.fast_tools module<a class="headerlink" href="#module-lnpy.lnp.fast_tools" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="lnpy.lnp.fast_tools.calc_auc">
<tt class="descclassname">lnpy.lnp.fast_tools.</tt><tt class="descname">calc_auc</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.fast_tools.calc_auc" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for c-based AUC calculation</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.fast_tools.calc_auc_trials">
<tt class="descclassname">lnpy.lnp.fast_tools.</tt><tt class="descname">calc_auc_trials</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.fast_tools.calc_auc_trials" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for c-based AUC calculation (multiple trials)</p>
</dd></dl>

</div>
<div class="section" id="module-lnpy.lnp.glm">
<span id="lnpy-lnp-glm-module"></span><h2>lnpy.lnp.glm module<a class="headerlink" href="#module-lnpy.lnp.glm" title="Permalink to this headline">¶</a></h2>
<p>Generalized linear models (GLMs) for receptive field estimation</p>
<dl class="class">
<dt id="lnpy.lnp.glm.BernoulliGLM">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.glm.</tt><tt class="descname">BernoulliGLM</tt><big>(</big><em>optimize=True</em>, <em>metric='BernoulliLL'</em>, <em>tolerance=0.1</em>, <em>prior=&lt;lnpy.learn.pyhelper.PyGaussianPrior object at 0x2b9af33f5290&gt;</em>, <em>alpha=1.0</em>, <em>gamma=0.0</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.BernoulliGLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lnpy.lnp.base.LNPEstimator" title="lnpy.lnp.base.LNPEstimator"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.lnp.base.LNPEstimator</span></tt></a></p>
<p>Wrapper around the Bernoulli GLM in the learn module</p>
<p>For a description of the arguments see lnpy.lnp.cbrf.CbRF</p>
<dl class="method">
<dt id="lnpy.lnp.glm.BernoulliGLM.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.BernoulliGLM.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train model and extract parameters</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lnpy.lnp.glm.GaussianGLM">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.glm.</tt><tt class="descname">GaussianGLM</tt><big>(</big><em>optimize=True</em>, <em>metric='MSE'</em>, <em>verbose=-1</em>, <em>tolerance=0.1</em>, <em>fit_bias=True</em>, <em>prior=&lt;lnpy.learn.pyhelper.PyGaussianPrior object at 0x2b9af33f5070&gt;</em>, <em>alpha=0.1</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.GaussianGLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lnpy.lnp.base.LNPEstimator" title="lnpy.lnp.base.LNPEstimator"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.lnp.base.LNPEstimator</span></tt></a></p>
<p>GLM with Gausian distribution of response values</p>
<p>For a description of the other arguments see lnpy.lnp.cbrf.CbRF</p>
<dl class="attribute">
<dt id="lnpy.lnp.glm.GaussianGLM.algorithm">
<tt class="descname">algorithm</tt><a class="headerlink" href="#lnpy.lnp.glm.GaussianGLM.algorithm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.glm.GaussianGLM.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.GaussianGLM.fit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="lnpy.lnp.glm.PoissonGLM">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.glm.</tt><tt class="descname">PoissonGLM</tt><big>(</big><em>optimize=True</em>, <em>metric='PoissonLL'</em>, <em>tolerance=1e-05</em>, <em>canonical=True</em>, <em>fit_bias=True</em>, <em>prior=&lt;lnpy.learn.pyhelper.PyGaussianPrior object at 0x2b9af33f5c70&gt;</em>, <em>alpha=1</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.PoissonGLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lnpy.lnp.base.LNPEstimator" title="lnpy.lnp.base.LNPEstimator"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.lnp.base.LNPEstimator</span></tt></a></p>
<p>GLM with Poisson distribution of response values</p>
<p>For a description of the other arguments see lnpy.lnp.cbrf.CbRF</p>
<dl class="attribute">
<dt id="lnpy.lnp.glm.PoissonGLM.algorithm">
<tt class="descname">algorithm</tt><a class="headerlink" href="#lnpy.lnp.glm.PoissonGLM.algorithm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.glm.PoissonGLM.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.PoissonGLM.fit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="lnpy.lnp.glm.StochasticGLM">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.glm.</tt><tt class="descname">StochasticGLM</tt><big>(</big><em>optimize=True</em>, <em>metric='logli_poissonexp'</em>, <em>family='poisson'</em>, <em>link='log'</em>, <em>alpha=0.01</em>, <em>n_epochs=1</em>, <em>algorithm='sgd'</em>, <em>suffix=''</em>, <em>verbose=1</em>, <em>weighting='permutation'</em>, <em>n_jobs=None</em>, <em>param_range=None</em>, <em>avg_decay=2.0</em>, <em>warm_start=False</em>, <em>n_iter=5</em>, <em>n_steps=7</em>, <em>bias_multiplier=1.0</em><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.StochasticGLM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lnpy.lnp.base.LNPEstimator" title="lnpy.lnp.base.LNPEstimator"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.lnp.base.LNPEstimator</span></tt></a></p>
<p>Stochastic gradient descent approximation to GLM</p>
<p>Approximates the solution to the CbRF method by stochastic gradient
descent.</p>
<blockquote>
<div>Parameters</div></blockquote>
<dl class="docutils">
<dt>optimize <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd>Perform automatic model optimization?</dd>
<dt>metric <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>The metric used for model optimization, e.g., &#8216;AUC&#8217; or &#8216;MI&#8217;</dd>
<dt>loss <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;hinge&#8217;, &#8216;squared_hinge&#8217;, &#8216;log&#8217;}</span></dt>
<dd>Loss function</dd>
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Regularization parameter</dd>
<dt>n_epochs <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Number of SGD iterations over the data set</dd>
<dt>algorithm <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;sgd&#8217;, &#8216;asgd&#8217;}</span></dt>
<dd>Plain SGD (&#8216;sgd&#8217;) or polynomial averaging SGD (&#8216;asgd&#8217;)</dd>
<dt>avg_decay <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>decay factor of asgd algorithm with avg_decay &gt;= 0</dd>
<dt>warm_start <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd>initialize SGD algorithm with current parameters or reset
parameters before each training</dd>
<dt>suffix <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>Prepend string to method name for easier result handling</dd>
<dt>verbose <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd>be verbose</dd>
<dt>n_jobs <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>Number of processes used for optimization</dd>
<dt>param_range <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>Min. and max. initial cost parameters</dd>
<dt>weighting <span class="classifier-delimiter">:</span> <span class="classifier">{&#8216;permutation&#8217;, &#8216;inv_prob&#8217;}</span></dt>
<dd>Permute samples from spike and no spike classes or use inverse
class priors?</dd>
</dl>
<dl class="attribute">
<dt id="lnpy.lnp.glm.StochasticGLM.alpha">
<tt class="descname">alpha</tt><a class="headerlink" href="#lnpy.lnp.glm.StochasticGLM.alpha" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="lnpy.lnp.glm.StochasticGLM.b">
<tt class="descname">b</tt><a class="headerlink" href="#lnpy.lnp.glm.StochasticGLM.b" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.glm.StochasticGLM.learn">
<tt class="descname">learn</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.StochasticGLM.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Train model and extract parameters</p>
</dd></dl>

<dl class="attribute">
<dt id="lnpy.lnp.glm.StochasticGLM.name">
<tt class="descname">name</tt><a class="headerlink" href="#lnpy.lnp.glm.StochasticGLM.name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="lnpy.lnp.glm.StochasticGLM.reset">
<tt class="descname">reset</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.glm.StochasticGLM.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets algorithm parameters to initial values</p>
</dd></dl>

<dl class="attribute">
<dt id="lnpy.lnp.glm.StochasticGLM.w">
<tt class="descname">w</tt><a class="headerlink" href="#lnpy.lnp.glm.StochasticGLM.w" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lnpy.lnp.mid">
<span id="lnpy-lnp-mid-module"></span><h2>lnpy.lnp.mid module<a class="headerlink" href="#module-lnpy.lnp.mid" title="Permalink to this headline">¶</a></h2>
<p>Maximum informative dimensions (MID) solver (Sharpee et al. 2004)</p>
<p>This is a wrapper around the MID solver by TO Sharpee available at:</p>
<p><a class="reference external" href="https://github.com/sharpee/mid">https://github.com/sharpee/mid</a></p>
<p>You have to put the executable in the same directory as this file.</p>
<p>Remark: Currently, only the 1D solver is working properly!</p>
<dl class="class">
<dt id="lnpy.lnp.mid.MID">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.mid.</tt><tt class="descname">MID</tt><big>(</big><em>bins=50</em>, <em>n_iter=50</em>, <em>tempdir=None</em>, <em>ndim=1</em>, <em>n_iter2=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.mid.MID" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lnpy.lnp.base.LNPEstimator" title="lnpy.lnp.base.LNPEstimator"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.lnp.base.LNPEstimator</span></tt></a></p>
<p>MID analysis (Sharpee et al. Neural Comput 2004)</p>
<p>Receptive field estimation based on maximization of mutual
information (MI) between stimulus and response</p>
<dl class="method">
<dt id="lnpy.lnp.mid.MID.__params2xml__">
<tt class="descname">__params2xml__</tt><big>(</big><em>prefix</em>, <em>xmlfile</em>, <em>stim_file</em>, <em>resp_file</em>, <em>rfsize</em>, <em>bins</em>, <em>n_iter</em><big>)</big><a class="headerlink" href="#lnpy.lnp.mid.MID.__params2xml__" title="Permalink to this definition">¶</a></dt>
<dd><p>Write estimation parameters to XML file</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.mid.MID.learn">
<tt class="descname">learn</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.mid.MID.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimates RF from given data by MI maximization</p>
<dl class="docutils">
<dt>Inputs:</dt>
<dd><dl class="first docutils">
<dt>X - array holding stimulus data with dimensions</dt>
<dd>(samples, features)</dd>
</dl>
<p class="last">y - array holding spike counts with dimesions (samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="lnpy.lnp.mid.MID.name">
<tt class="descname">name</tt><a class="headerlink" href="#lnpy.lnp.mid.MID.name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lnpy.lnp.setup">
<span id="lnpy-lnp-setup-module"></span><h2>lnpy.lnp.setup module<a class="headerlink" href="#module-lnpy.lnp.setup" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="lnpy.lnp.setup.configuration">
<tt class="descclassname">lnpy.lnp.setup.</tt><tt class="descname">configuration</tt><big>(</big><em>parent_package=''</em>, <em>top_path=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.setup.configuration" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-lnpy.lnp.sta">
<span id="lnpy-lnp-sta-module"></span><h2>lnpy.lnp.sta module<a class="headerlink" href="#module-lnpy.lnp.sta" title="Permalink to this headline">¶</a></h2>
<p>Spike-triggered average (STA) stimulus</p>
<dl class="class">
<dt id="lnpy.lnp.sta.STA">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.sta.</tt><tt class="descname">STA</tt><big>(</big><em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.sta.STA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lnpy.lnp.base.LNPEstimator" title="lnpy.lnp.base.LNPEstimator"><tt class="xref py py-class docutils literal"><span class="pre">lnpy.lnp.base.LNPEstimator</span></tt></a></p>
<p>Spike-triggered average (STA) reptive field estimator</p>
<dl class="method">
<dt id="lnpy.lnp.sta.STA.fit">
<tt class="descname">fit</tt><big>(</big><em>X</em>, <em>Y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.sta.STA.fit" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lnpy.lnp.tools">
<span id="lnpy-lnp-tools-module"></span><h2>lnpy.lnp.tools module<a class="headerlink" href="#module-lnpy.lnp.tools" title="Permalink to this headline">¶</a></h2>
<p>Some helper for LNP model estimation</p>
<dl class="class">
<dt id="lnpy.lnp.tools.DataConverter">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">DataConverter</tt><big>(</big><em>transform</em>, <em>win_len=array(0.1) * s</em>, <em>samplerate=array(500.0) * Hz</em>, <em>verbose=False</em>, <em>n_samples=inf</em>, <em>scaling='dB'</em>, <em>dynamic_range=60.0</em>, <em>center=True</em>, <em>normalize=True</em>, <em>timesteps=None</em>, <em>multi_spike_warning=False</em>, <em>history_len=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.DataConverter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>Converts neo block to stimulus and response matrices</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transform</strong> (<em>An instance derived from class BaseTransform</em>) &#8211; Object used for time-frequency or modulation analysis</li>
<li><strong>win_len</strong> (<em>float</em>) &#8211; the temporal window length preceding the response</li>
<li><strong>sample_rate</strong> (<em>float</em>) &#8211; sampling frequency of the features in the stimulus matrix</li>
<li><strong>freq_lim</strong> (<em>list</em>) &#8211; upper and lower frequency limits [obsolete; use samplerate of
transform]</li>
<li><strong>filters_per_erb</strong> (<em>float</em>) &#8211; number of filters per ERB of gammatone filterbank [obsolete]</li>
<li><strong>verbose</strong> (<em>boolean</em>) &#8211; output some information</li>
<li><strong>n_samples</strong> (<em>int</em>) &#8211; the maximum number of samples</li>
<li><strong>scaling</strong> (<em>{&#8216;dB&#8217;, &#8216;decible&#8217;, &#8216;none&#8217;}</em>) &#8211; scaling of spectro-temporal amplitudes</li>
<li><strong>dynamic_range</strong> (<em>float</em>) &#8211; limit amplitude range (after scaling) to dynamic_range below max.
value</li>
<li><strong>center</strong> (<em>boolean</em>) &#8211; normalize each feature dimension to zero mean</li>
<li><strong>timesteps</strong> (<em>list</em>) &#8211; time steps preceding the response for modulation features</li>
<li><strong>multi_spike_warning</strong> (<em>bool, optional</em>) &#8211; print warning if more than one spike is located in a time bin</li>
<li><strong>history_len</strong> (<em>float, optional</em>) &#8211; length of the post-spike history term in seconds. If history_len &gt; 0,
the post-spike history will be appended to the end of the feature
vectors. Defaults to None (no history term).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lnpy.lnp.tools.DataConverter.process">
<tt class="descname">process</tt><big>(</big><em>block</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.DataConverter.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert stimulus/response data set to matrices</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>block</strong> (<em>neo block</em>) &#8211; Neo block containing stimulus and response data</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><ul class="simple">
<li><strong>stim_mat</strong> (<em>numpy array</em>) &#8211;
n x d array (n samples x d features)</li>
<li><strong>spike_mat</strong> (<em>numpy array</em>) &#8211;
n x m array (n samples x m trials)</li>
<li><strong>patch_size</strong> (<em>list</em>) &#8211;
dimensionality of the RF patch</li>
<li><strong>axes</strong> (<em>list</em>) &#8211;
list of Axis instances</li>
<li><strong>stim_offset</strong> (<em>numpy array</em>) &#8211;
offset positions of single stimuli</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="lnpy.lnp.tools.DataConverter.unwrap_data">
<em class="property">static </em><tt class="descname">unwrap_data</tt><big>(</big><em>n_samples</em>, <em>n_trials</em>, <em>stim_offset</em>, <em>stim_perm</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.DataConverter.unwrap_data" title="Permalink to this definition">¶</a></dt>
<dd><p>get order of (trial-)unwrapped stimulus and response examples</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lnpy.lnp.tools.ModelBootstrapper">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">ModelBootstrapper</tt><big>(</big><em>model</em>, <em>size=0.1</em>, <em>runs=100</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ModelBootstrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>Bootstrapping of RF model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>neuropy.receptivefields.BaseEstimator</em>) &#8211; a fitted model</li>
<li><strong>size</strong> (<em>float, optional</em>) &#8211; fraction of the data used for each bootstrap run. Defaults to 0.1</li>
<li><strong>runs</strong> (<em>int, optional</em>) &#8211; number of bootstrap runs. Defaults to 100.</li>
<li><strong>verbose</strong> (<em>bool, optional</em>) &#8211; tell something. Defaults to False.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lnpy.lnp.tools.ModelBootstrapper.process">
<tt class="descname">process</tt><big>(</big><em>X</em>, <em>Y</em>, <em>return_models=False</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ModelBootstrapper.process" title="Permalink to this definition">¶</a></dt>
<dd><p>run bootstrapping on data with trained model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>array-like</em>) &#8211; stimulus data with dimensions: observations x features</li>
<li><strong>Y</strong> (<em>array-like</em>) &#8211; spike data with dimensions: observations x trials</li>
<li><strong>return_models</strong> (<em>bool, optional</em>) &#8211; return models for each run if True. Otherwise the standard
deviation across all runs. Defaults to False</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>W</strong> &#8211;
array with bootstrapped models (one per row)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lnpy.lnp.tools.ResultCollection">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">ResultCollection</tt><big>(</big><em>datasets</em>, <em>method_dirs</em>, <em>method_names=None</em>, <em>verbose=True</em>, <em>ignore_nan=True</em>, <em>method_is_prefix=True</em>, <em>remove_duplicates=True</em>, <em>what='default'</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>Convenience class to simplify analysis of RF results</p>
<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.__collect__">
<tt class="descname">__collect__</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.__collect__" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect data</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.calc_normalized_projection">
<tt class="descname">calc_normalized_projection</tt><big>(</big><em>ref_name</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.calc_normalized_projection" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate normalized subspace projections given a reference method</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.calc_tuning">
<tt class="descname">calc_tuning</tt><big>(</big><em>upsample=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.calc_tuning" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate best frequency and spectral bandwidth of STRFs</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.calc_wilcoxon">
<tt class="descname">calc_wilcoxon</tt><big>(</big><em>metric='MI'</em>, <em>correction=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.calc_wilcoxon" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a Wilcoxon signed-rank test for all combinations of methods
and returns an upper triangular matrix with p-values</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>metric</strong> (<em>str</em>) &#8211; metric to evaluate</li>
<li><strong>correction</strong> (<em>str</em>) &#8211; <p>correct for multiple comparisons. The argument is passed to
statsmodels.sandbox.stats.multicomp.multipletests. Possible
values:</p>
<p><cite>bonferroni</cite> : one-step correction
<cite>sidak</cite> : one-step correction
<cite>holm-sidak</cite> : step down method using Sidak adjustments
<cite>holm</cite> : step-down method using Bonferroni adjustments
<cite>simes-hochberg</cite> : step-up method  (independent)
<cite>hommel</cite> : closed method based on Simes tests (non-negative)
<cite>fdr_bh</cite> : Benjamini/Hochberg  (non-negative)
<cite>fdr_by</cite> : Benjamini/Yekutieli (negative)
<cite>fdr_tsbh</cite> : two stage fdr correction (non-negative)
<cite>fdr_tsbky</cite> : two stage fdr correction (non-negative)</p>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.getCVResults">
<tt class="descname">getCVResults</tt><big>(</big><em>metric='MI'</em>, <em>methods=None</em>, <em>what='folds'</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.getCVResults" title="Permalink to this definition">¶</a></dt>
<dd><p>Return cross-validated prediction performance</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>what</strong> (<em>str</em>) &#8211; <p>What to return?</p>
<p>&#8216;folds&#8217; = cv folds
&#8216;mean&#8217; = mean of all cv folds</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.get_RF">
<tt class="descname">get_RF</tt><big>(</big><em>method=None</em>, <em>datasets=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.get_RF" title="Permalink to this definition">¶</a></dt>
<dd><p>Return RF for given method and data set</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.get_RFs">
<tt class="descname">get_RFs</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.get_RFs" title="Permalink to this definition">¶</a></dt>
<dd><p>Return all RF objects</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.get_dataset_count">
<tt class="descname">get_dataset_count</tt><big>(</big><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.get_dataset_count" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the number of collected data sets</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.get_runtime">
<tt class="descname">get_runtime</tt><big>(</big><em>fit_only=False</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.get_runtime" title="Permalink to this definition">¶</a></dt>
<dd><p>Return algorithm run time (in seconds)</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.plot_kurtosis">
<tt class="descname">plot_kurtosis</tt><big>(</big><em>method1</em>, <em>method2</em>, <em>ax=None</em>, <em>figsize=(3.27</em>, <em>3.27)</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.plot_kurtosis" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates scatter plot of kurtosis of RF coefficients (sparseness)</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.plot_scatter">
<tt class="descname">plot_scatter</tt><big>(</big><em>method1</em>, <em>method2</em>, <em>metric='MI'</em>, <em>unit='bits'</em>, <em>ax=None</em>, <em>filename=None</em>, <em>figsize=(3.27</em>, <em>3.27)</em>, <em>figformat='pdf'</em>, <em>show_pval=True</em>, <em>show_N=True</em>, <em>correction=None</em>, <em>index_markers=False</em>, <em>markerfacecolors=None</em>, <em>minval=None</em>, <em>maxval=None</em>, <em>markersize=5</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.plot_scatter" title="Permalink to this definition">¶</a></dt>
<dd><p>Create nice scatter plot</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.plot_tuning">
<tt class="descname">plot_tuning</tt><big>(</big><em>method1</em>, <em>method2</em>, <em>upsample=3.0</em>, <em>create_fig=True</em>, <em>ax_BF=None</em>, <em>ax_eBW=None</em>, <em>ax_iBW=None</em>, <em>fscale='lin'</em>, <em>logbase=250</em>, <em>aspect_image=True</em>, <em>funit='Hz'</em>, <em>axlim=None</em>, <em>add_cc_line=False</em>, <em>add_cc_text=False</em>, <em>cc_text_kw=None</em>, <em>markersize=5</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.plot_tuning" title="Permalink to this definition">¶</a></dt>
<dd><p>Displays the following frequency tuning properties for the given
.. method:: - bets frequency (BF)</p>
<dl class="method">
<dt>
<tt class="descname">- excitatory bandwidth (eBW)</tt></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<tt class="descname">- inhibitory bandwidth (iBW)</tt></dt>
<dd></dd></dl>

</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.print_RFs">
<tt class="descname">print_RFs</tt><big>(</big><em>method_names</em>, <em>pdf_file</em>, <em>dsets=None</em>, <em>rows_per_page=10</em>, <em>cc_ref_name=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.print_RFs" title="Permalink to this definition">¶</a></dt>
<dd><p>print all RFs to a (potentially long) pdf file</p>
</dd></dl>

<dl class="method">
<dt id="lnpy.lnp.tools.ResultCollection.smooth_RFs">
<tt class="descname">smooth_RFs</tt><big>(</big><em>filtsize=(3</em>, <em>3)</em>, <em>scale=1</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.ResultCollection.smooth_RFs" title="Permalink to this definition">¶</a></dt>
<dd><p>smooth all RFs in result collection using 2D Gaussian</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="lnpy.lnp.tools.SimpleCell">
<em class="property">class </em><tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">SimpleCell</tt><big>(</big><em>pattern</em>, <em>threshold=2.0</em>, <em>stddev=0.5</em>, <em>n_trials=1</em>, <em>rectify=True</em>, <em>dtype=&lt;type 'numpy.float64'&gt;</em>, <em>seed=None</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.SimpleCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple cell simulation based on linear-nonlinear model</p>
<p>Create one or more spike trains using a given receptive field</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>pattern</strong> (<em>ndarray</em>) &#8211; The true RF of the model cell</li>
<li><strong>threshold</strong> (<em>float</em>) &#8211; Spiking threshold in terms of standard deviations of filtered
stimulus</li>
<li><strong>stddev</strong> (<em>float</em>) &#8211; Standard deviation of the Gaussian noise around the threshold</li>
<li><strong>n_trials</strong> (<em>int</em>) &#8211; Number of trials</li>
<li><strong>rectify</strong> (<em>boolean</em>) &#8211; Set negative filtered values to zero?</li>
<li><strong>dtype</strong> (<em>numpy.dtype</em>) &#8211; The data type of the response values</li>
<li><strong>seed</strong> (<em>int or None</em>) &#8211; The seed for the random number generator</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="lnpy.lnp.tools.SimpleCell.simulate">
<tt class="descname">simulate</tt><big>(</big><em>S</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.SimpleCell.simulate" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates spike for given input stimulus</p>
<dl class="docutils">
<dt>Input:</dt>
<dd>S - stimulus array with dimensions (samples, features)</dd>
<dt>Output:</dt>
<dd>0-1-valued spike array with dimensions (samples, n_trials)</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcAUC">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcAUC</tt><big>(</big><em>Y</em>, <em>score</em>, <em>num=250</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcAUC" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate area under ROC curve</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcCoherence">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcCoherence</tt><big>(</big><em>pred</em>, <em>Y</em>, <em>nfft=256</em>, <em>noverlap=128</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcCoherence" title="Permalink to this definition">¶</a></dt>
<dd><p>Coherence between true and predicted response</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcDPrime">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcDPrime</tt><big>(</big><em>stim</em>, <em>spikes</em>, <em>k</em>, <em>equal_variance=False</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcDPrime" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate d-prime between spike-conditional and no spike-conditional
distributions</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcKLD">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcKLD</tt><big>(</big><em>stim_mat</em>, <em>spike_mat</em>, <em>k</em>, <em>num_bins=50</em>, <em>distributions=False</em>, <em>correct_bias=False</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcKLD" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate KLD between conditional distributions of projections</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcLogLikelihood">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcLogLikelihood</tt><big>(</big><em>z</em>, <em>Y</em>, <em>dt=1.0</em>, <em>family='poissonexp'</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcLogLikelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>compute negative log likelihood for a given GLM family</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcMI">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcMI</tt><big>(</big><em>*args</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcMI" title="Permalink to this definition">¶</a></dt>
<dd><p>Short-named version of MI calculation routine</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcMutualInformation">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcMutualInformation</tt><big>(</big><em>Y</em>, <em>z</em>, <em>n_bins=50</em>, <em>distributions=False</em>, <em>correct_bias=False</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcMutualInformation" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate mutual information transmitted by the RF k</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcROC">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcROC</tt><big>(</big><em>proj</em>, <em>spikes</em>, <em>n_steps=250</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcROC" title="Permalink to this definition">¶</a></dt>
<dd><p>slow way of computing the ROC curve</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.calcSWDF">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">calcSWDF</tt><big>(</big><em>wf</em>, <em>bins=25</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.calcSWDF" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Calculates spike waveform density function of spike waveform matrix</dt>
<dd>every row in the matrix is assumed to represent a spike waveform</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.createGrating">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">createGrating</tt><big>(</big><em>size=(25</em>, <em>25)</em>, <em>angle=45.0</em>, <em>phase=0.0</em>, <em>f=0.5</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.createGrating" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates single sinusoidal grating of given size</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>size</strong> (<em>tuple, list, ndarray</em>) &#8211; The size of the grating</li>
<li><strong>angle</strong> (<em>float</em>) &#8211; The angle in defees</li>
<li><strong>phase</strong> (<em>float</em>) &#8211; The phase in radians</li>
<li><strong>f</strong> (<em>float</em>) &#8211; Normalized frequency</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.createGratings">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">createGratings</tt><big>(</big><em>size=(25</em>, <em>25)</em>, <em>N=10000</em>, <em>center=True</em>, <em>dtype=&lt;type 'numpy.float64'&gt;</em>, <em>whiten=False</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.createGratings" title="Permalink to this definition">¶</a></dt>
<dd><p>Create ensemble of sinusoidal gratings with random parameters</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>size</strong> (<em>tuple, list, ndarray</em>) &#8211; The size of the grating</li>
<li><strong>N</strong> (<em>int</em>) &#8211; The number of gratings</li>
<li><strong>center</strong> (<em>boolean</em>) &#8211; Element-wise centering of grating ensemble</li>
<li><strong>dtype</strong> (<em>numpy.dtype</em>) &#8211; Data type of gratings</li>
<li><strong>whiten</strong> (<em>boolean</em>) &#8211; PCA-based whitening of grating matrix?</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.createRF">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">createRF</tt><big>(</big><em>name='gabor'</em>, <em>size=(25</em>, <em>25)</em>, <em>angle=45.0</em>, <em>phase=0.0</em>, <em>frequency=0.5</em>, <em>sigma=(0.35</em>, <em>0.35)</em>, <em>threshold=0.01</em>, <em>dtype=&lt;type 'float'&gt;</em>, <em>xoffset=0</em>, <em>yoffset=0</em>, <em>extent=(-8</em>, <em>4</em>, <em>-7</em>, <em>5)</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.createRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Create artificial receptive field pattern</p>
<p>Currently available: &#8216;gabor&#8217; and &#8216;onset&#8217;</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.create_gabor_rf">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">create_gabor_rf</tt><big>(</big><em>size_x</em>, <em>size_y</em>, <em>mu_x</em>, <em>mu_y</em>, <em>sigma_x</em>, <em>sigma_y</em>, <em>angle=45</em>, <em>frequency=0.5</em>, <em>phase=0.0</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.create_gabor_rf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.create_onset_rf">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">create_onset_rf</tt><big>(</big><em>size_x</em>, <em>size_y</em>, <em>mu_x</em>, <em>mu_y</em>, <em>sigma_x</em>, <em>sigma_y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.create_onset_rf" title="Permalink to this definition">¶</a></dt>
<dd><p>return narrow-band onset RF</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.loadImages">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">loadImages</tt><big>(</big><em>location</em>, <em>samples=100</em>, <em>size=(25</em>, <em>25)</em>, <em>center=True</em>, <em>randomize=False</em>, <em>scale=0.5</em>, <em>images=10</em>, <em>normalize=True</em>, <em>dtype=&lt;type 'numpy.float64'&gt;</em>, <em>remove_dc=True</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.loadImages" title="Permalink to this definition">¶</a></dt>
<dd><p>Load van Hateren images and recasts them as vectors in a stimulus matrix</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.segment">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">segment</tt><big>(</big><em>data</em>, <em>seg_len</em>, <em>shift</em>, <em>zero_padding=True</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.segment" title="Permalink to this definition">¶</a></dt>
<dd><p>Rearranges a vector by buffering overlapping segments as rows</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<em>array-like</em>) &#8211; a vector (or flattened view) of the array to be segmented</li>
<li><strong>seg_len</strong> (<em>int</em>) &#8211; length of each segment in samples</li>
<li><strong>shift</strong> (<em>int</em>) &#8211; the segment shift in samples</li>
<li><strong>zero_padding</strong> (<em>bool, optional</em>) &#8211; append zeros to data if data does not contain enough
samples to fill all segments. If set to False, the
last segment will be omitted. Defaults to True.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.smoothRF">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">smoothRF</tt><big>(</big><em>rf</em>, <em>filtsize=(3</em>, <em>3)</em>, <em>scale=1</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.smoothRF" title="Permalink to this definition">¶</a></dt>
<dd><p>smooth 2D RF using 2D Gaussian filter</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.update_progress">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">update_progress</tt><big>(</big><em>progress</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.update_progress" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple console-based progress bar</p>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.vdotNormal">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">vdotNormal</tt><big>(</big><em>x</em>, <em>y</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.vdotNormal" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalized projection (aka correlation) between to arrays</p>
<p>This functions calculates the normalized projection between two
vectors x and y. If x and/or are matrices the normalized projection
between the flattened arrays is calculated.</p>
<dl class="docutils">
<dt>Inputs:</dt>
<dd>x,y (numpy arrays)</dd>
<dt>Outputs:</dt>
<dd>z - A scalar between -1. and 1.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="lnpy.lnp.tools.whiten_matrix">
<tt class="descclassname">lnpy.lnp.tools.</tt><tt class="descname">whiten_matrix</tt><big>(</big><em>X</em>, <em>eps=1e-12</em><big>)</big><a class="headerlink" href="#lnpy.lnp.tools.whiten_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>whitening of data matrix using PCA</p>
</dd></dl>

</div>
<div class="section" id="module-lnpy.lnp">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-lnpy.lnp" title="Permalink to this headline">¶</a></h2>
<div class="section" id="receptive-fields">
<h3>Receptive fields<a class="headerlink" href="#receptive-fields" title="Permalink to this headline">¶</a></h3>
<p>A subpackage that provides a bunch of receptive field estimation methods</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">lnpy.lnp package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp.base">lnpy.lnp.base module</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp.cbrf">lnpy.lnp.cbrf module</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp.fast_tools">lnpy.lnp.fast_tools module</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp.glm">lnpy.lnp.glm module</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp.mid">lnpy.lnp.mid module</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp.setup">lnpy.lnp.setup module</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp.sta">lnpy.lnp.sta module</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp.tools">lnpy.lnp.tools module</a></li>
<li><a class="reference internal" href="#module-lnpy.lnp">Module contents</a><ul>
<li><a class="reference internal" href="#receptive-fields">Receptive fields</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="lnpy.learn.html"
                        title="previous chapter">lnpy.learn package</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="lnpy.transform.html"
                        title="next chapter">lnpy.transform package</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/lnpy.lnp.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="lnpy.transform.html" title="lnpy.transform package"
             >next</a> |</li>
        <li class="right" >
          <a href="lnpy.learn.html" title="lnpy.learn package"
             >previous</a> |</li>
        <li><a href="index.html">lnpy 0.1 alpha documentation</a> &raquo;</li>
          <li><a href="lnpy.html" >lnpy package</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2015, Arne F. Meyer.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>